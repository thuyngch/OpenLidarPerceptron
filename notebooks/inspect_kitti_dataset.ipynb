{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thuync/Workspace/OpenLidarPerceptron\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, cv2, copy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils, box_utils\n",
    "from pcdet.config import cfg, log_config_to_file, cfg_from_list, cfg_from_yaml_file\n",
    "\n",
    "\n",
    "# Move to the root directory\n",
    "if not 'workdir' in globals():\n",
    "    workdir = os.getcwd()\n",
    "    workdir = \"/\".join(workdir.split('/')[:-1])\n",
    "%cd \"$workdir\"\n",
    "\n",
    "# Create cache folder\n",
    "os.makedirs(\"cache\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "workers = 4\n",
    "dist_train = False\n",
    "cfg_file = \"tools/cfgs/kitti_models/pointpillar_gn.yaml\"\n",
    "log_file = \"cache/dataset_debug.txt\"\n",
    "\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "logger = common_utils.create_logger(log_file, rank=cfg.LOCAL_RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=batch_size,\n",
    "    dist=dist_train, workers=workers,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    ")\n",
    "\n",
    "print(\"Dataset size:\", len(train_set))\n",
    "print(\"Classnames:\", train_set.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data_batch = train_set[idx]\n",
    "print(\"Batch components:\", data_batch.keys())\n",
    "\n",
    "points = data_batch['points']\n",
    "frame_id = data_batch['frame_id']\n",
    "gt_boxes = data_batch['gt_boxes']\n",
    "use_lead_xyz = data_batch['use_lead_xyz']\n",
    "voxels = data_batch['voxels']\n",
    "voxel_coords = data_batch['voxel_coords']\n",
    "voxel_num_points = data_batch['voxel_num_points']\n",
    "image_shape = data_batch['image_shape']\n",
    "\n",
    "for key, val in data_batch.items():\n",
    "    if isinstance(val, (str, bool)):\n",
    "        print(\"{}: {}\".format(key, val))\n",
    "    else:\n",
    "        print(\"{}: {}\".format(key, val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_idx = 100\n",
    "print(points[point_idx])\n",
    "print(voxel_coords[point_idx])\n",
    "print(voxels[point_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.unique(voxel_coords[:,0])\n",
    "ys = np.unique(voxel_coords[:,1])\n",
    "zs = np.unique(voxel_coords[:,2])\n",
    "print(\"voxel_coords unique:\", len(xs), len(ys), len(zs))\n",
    "\n",
    "print(\"gt_boxes:\", gt_boxes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuync/Workspace/OpenLidarPerceptron/pcdet/config.py:73: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  new_config = yaml.load(f)\n",
      "/home/thuync/Workspace/OpenLidarPerceptron/pcdet/config.py:54: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_config = yaml.load(f)\n",
      "2020-07-07 16:23:04,335   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2020-07-07 16:23:04,336   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2020-07-07 16:23:04,337   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2020-07-07 16:23:04,362   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2020-07-07 16:23:04,367   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2020-07-07 16:23:04,369   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2020-07-07 16:23:04,435   INFO  Loading KITTI dataset\n",
      "2020-07-07 16:23:04,574   INFO  Total samples for KITTI dataset: 3712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3712\n",
      "Classnames: ['Car', 'Pedestrian', 'Cyclist']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "workers = 4\n",
    "dist_train = False\n",
    "cfg_file = \"tools/cfgs/kitti_models/pv_rcnn.yaml\"\n",
    "log_file = \"cache/dataset_debug.txt\"\n",
    "\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "logger = common_utils.create_logger(log_file, rank=cfg.LOCAL_RANK)\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=batch_size,\n",
    "    dist=dist_train, workers=workers,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    ")\n",
    "print(\"Dataset size:\", len(train_set))\n",
    "print(\"Classnames:\", train_set.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "info = copy.deepcopy(train_set.kitti_infos[index])\n",
    "sample_idx = info['point_cloud']['lidar_idx']\n",
    "\n",
    "points = train_set.get_lidar(sample_idx)\n",
    "calib = train_set.get_calib(sample_idx)\n",
    "\n",
    "img_shape = info['image']['image_shape']\n",
    "if train_set.dataset_cfg.FOV_POINTS_ONLY:\n",
    "    pts_rect = calib.lidar_to_rect(points[:, 0:3])\n",
    "    fov_flag = train_set.get_fov_flag(pts_rect, img_shape, calib)\n",
    "    points = points[fov_flag]\n",
    "\n",
    "input_dict = {\n",
    "    'points': points,\n",
    "    'frame_id': sample_idx,\n",
    "    'calib': calib,\n",
    "}\n",
    "\n",
    "if 'annos' in info:\n",
    "    annos = info['annos']\n",
    "    annos = common_utils.drop_info_with_name(annos, name='DontCare')\n",
    "    loc, dims, rots = annos['location'], annos['dimensions'], annos['rotation_y']\n",
    "    gt_names = annos['name']\n",
    "    gt_boxes_camera = np.concatenate([loc, dims, rots[..., np.newaxis]], axis=1).astype(np.float32)\n",
    "    gt_boxes_lidar = box_utils.boxes3d_kitti_camera_to_lidar(gt_boxes_camera, calib)\n",
    "\n",
    "    input_dict.update({\n",
    "        'gt_names': gt_names,\n",
    "        'gt_boxes': gt_boxes_lidar\n",
    "    })\n",
    "    road_plane = train_set.get_road_plane(sample_idx)\n",
    "    if road_plane is not None:\n",
    "        input_dict['road_plane'] = road_plane\n",
    "\n",
    "data_dict = train_set.prepare_data(data_dict=input_dict)\n",
    "data_dict['image_shape'] = img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info keys: dict_keys(['point_cloud', 'image', 'calib', 'annos'])\n",
      "\n",
      "point_cloud: {'num_features': 4, 'lidar_idx': '000176'} \n",
      "\n",
      "image: {'image_idx': '000176', 'image_shape': array([ 375, 1242], dtype=int32)} \n",
      "\n",
      "calib:\n",
      "\t'P2': shape (4, 4)\n",
      "\t'R0_rect': shape (4, 4)\n",
      "\t'Tr_velo_to_cam': shape (4, 4)\n",
      "\n",
      "annos:\n",
      "\t'name': shape (7,)\n",
      "\t'truncated': shape (7,)\n",
      "\t'occluded': shape (7,)\n",
      "\t'alpha': shape (7,)\n",
      "\t'bbox': shape (7, 4)\n",
      "\t'dimensions': shape (7, 3)\n",
      "\t'location': shape (7, 3)\n",
      "\t'rotation_y': shape (7,)\n",
      "\t'score': shape (7,)\n",
      "\t'difficulty': shape (7,)\n",
      "\t'index': shape (7,)\n",
      "\t'gt_boxes_lidar': shape (5, 7)\n",
      "\t'num_points_in_gt': shape (7,)\n",
      "\n",
      "points:\n",
      "\tsample_idx: 000176\n",
      "\tall points from lidar: (114115, 4)\n",
      "\tpoints in FOV: (19384, 4)\n",
      "\n",
      "gt_boxes_lidar: (5, 7)\n",
      "\n",
      "road_plane: (4,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine 'input_dict'\n",
    "\n",
    "print(\"info keys: {}\\n\".format(info.keys()))\n",
    "print(\"point_cloud:\", info['point_cloud'], '\\n')\n",
    "print(\"image:\", info['image'], '\\n')\n",
    "\n",
    "print('calib:')\n",
    "for key, val in info['calib'].items():\n",
    "    print(\"\\t'{}': shape {}\".format(key, val.shape))\n",
    "print()\n",
    "\n",
    "print('annos:')\n",
    "for key, val in info['annos'].items():\n",
    "    print(\"\\t'{}': shape {}\".format(key, val.shape))\n",
    "print()\n",
    "\n",
    "\n",
    "# Get 'points'\n",
    "print(\"points:\")\n",
    "print(\"\\tsample_idx:\", sample_idx)\n",
    "print(\"\\tall points from lidar:\", train_set.get_lidar(sample_idx).shape)\n",
    "print(\"\\tpoints in FOV:\", points.shape)\n",
    "print()\n",
    "\n",
    "# gt_boxes_lidar\n",
    "print(\"gt_boxes_lidar:\", gt_boxes_lidar.shape)\n",
    "print()\n",
    "\n",
    "# road_plane\n",
    "print(\"road_plane:\", road_plane.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dict: dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape'])\n"
     ]
    }
   ],
   "source": [
    "# Examine 'data_dict'\n",
    "print(\"data_dict:\", data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_thuync",
   "language": "python",
   "name": "3d_thuync"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
